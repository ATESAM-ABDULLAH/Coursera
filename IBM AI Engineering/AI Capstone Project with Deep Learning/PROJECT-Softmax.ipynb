{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e83116b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e84062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Procssing\n",
    "import pandas\n",
    "import matplotlib.pylab as plt #numpy + pyplot as 1 library\n",
    "\n",
    "#Image Processing\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "#File handling\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#Pytorch\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "#IBM library \n",
    "# import skillsnetworkb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0c13f",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**Link:** https://data.mendeley.com/datasets/5y9wdsg2zt/2\n",
    "\n",
    "**Size:** 203MB\n",
    "\n",
    "**Classes:** 2 - positive(cracked),negative(not cracked)\n",
    "\n",
    "**Images:** 40000 , 227 x 227, RGB channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f16e1",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33e93e",
   "metadata": {},
   "source": [
    "Function to plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab13da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + data_sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83403e",
   "metadata": {},
   "source": [
    "Function to plot image from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fd473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path,title):\n",
    "    image = Image.open(path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaffa90",
   "metadata": {},
   "source": [
    "Function to return list of images full path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf735ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_maker(directory,positive_directory,negative_directory):\n",
    "    positive_file_path = os.path.join(directory,positive_directory)\n",
    "    positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "    positive_files.sort()\n",
    "\n",
    "    negative_file_path = os.path.join(directory,negative_directory)\n",
    "    negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "    negative_files.sort()\n",
    "    \n",
    "    return positive_files,negative_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e681e",
   "metadata": {},
   "source": [
    "Function to build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae48f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Constructor\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      5\u001b[0m         directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/resources/data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/resources/data\"\n",
    "        positive=\"Positive\"\n",
    "        negative=\"Negative\"\n",
    "        \n",
    "        #define paths\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        \n",
    "        #make list of full image paths\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "        \n",
    "        #sort lists\n",
    "        positive_files.sort()\n",
    "        negative_files.sort()\n",
    "        \n",
    "        #total number of images\n",
    "        number_of_samples = len(positive_files) + len(negative_files)\n",
    "        \n",
    "        #Combine both list. Even = +ve, Odd = -ve\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        \n",
    "        #List of output class \n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        #Even = 1/positive, Odd = 0/negative\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        \n",
    "        #if train on [0-30000], val on [30000-40000]\n",
    "        if train:\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)\n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        #open image tensor and output\n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "          \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a8120",
   "metadata": {},
   "source": [
    "Function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77ffd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs,model,input_size):\n",
    "    for epoch in range(num_epochs):\n",
    "        #initialize model for training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        #Train model and optimize weights/bias\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.view(-1,input_size))\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #calculate loss and prediction per batch\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        #Calculate Training loss and accuracy per epoch\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = (correct_train / total_train) * 100\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracy.append(train_acc)\n",
    "        \n",
    "        #Initialize model for testing\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        #Turn off gradients for memory saving\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #Test model on Test data\n",
    "            for inputs, labels in validation_loader:\n",
    "                outputs = model(inputs.view(-1,input_size))\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "        #Calculate Validation loss and accuracy per epoch\n",
    "        test_loss = running_loss / len(validation_loader)\n",
    "        test_acc = (correct_test / total_test) * 100\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracy.append(test_acc)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% - '\n",
    "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "        \n",
    "        return train_loss,train_acc,test_loss,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b341822",
   "metadata": {},
   "source": [
    "Function to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f7a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(train_loss,train_acc,test_loss,test_acc):\n",
    "    # Plot training and testing loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and testing accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracy, label='Train Accuracy')\n",
    "    plt.plot(test_accuracy, label='Test Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da0bf1",
   "metadata": {},
   "source": [
    "## Steps to follow\n",
    "\n",
    "1. Download Data\n",
    "2. Make a transform compose\n",
    "3. Make Dataset objects\n",
    "4. Create softmax module\n",
    "5. Build softmax object\n",
    "6. Build optimizer and criterion\n",
    "7. Build Dataloader objects\n",
    "8. Train model\n",
    "9. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade5d44",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a482e95",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b2ff2c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mean \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m]\n\u001b[1;32m      2\u001b[0m std \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m transform \u001b[38;5;241m=\u001b[39m\u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([ transforms\u001b[38;5;241m.\u001b[39mToTensor(), transforms\u001b[38;5;241m.\u001b[39mNormalize(mean, std)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da3dbe",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dfa1d2e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_train\u001b[38;5;241m=\u001b[39m\u001b[43mDataset\u001b[49m(transform\u001b[38;5;241m=\u001b[39mtransform,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m dataset_val\u001b[38;5;241m=\u001b[39mDataset(transform\u001b[38;5;241m=\u001b[39mtransform,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train=Dataset(transform=transform,train=True)\n",
    "dataset_val=Dataset(transform=transform,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fafa27",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6395ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_image=3*227*227\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6924c0f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSoftmax\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_inputs, n_outputs):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class Softmax(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pred = self.linear(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4a335",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563afc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = size_of_image\n",
    "output_dim = 2 #1/0\n",
    "\n",
    "model_softmax = Softmax(input_dim,output_dim)\n",
    "print(model_softmax.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dda85",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2468610",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum_term = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model_softmax.parameters(), lr=learning_rate, momentum=momentum_term)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122e031",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 5\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size_train)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533ab5c",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81656766",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "train_model(n_epochs,model=model_softmax,input_size=input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac60ac67",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ac8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(train_losses,train_accuracy,test_loss,test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
